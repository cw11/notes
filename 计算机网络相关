计算机网络相关

1、计算机为什么要分层？
	因为internet很复杂。对于复杂的系统，分层有以下几点好处：
		（1）、使其结构非常清晰，清楚知道各层之间的关系
		（2）、模块化会使系统的维护、升级更简化，改变某一层服务的具体实现对系统其他部分透明（不影响）
	缺点：分层也有弊端，因为每层可能都要重复较低层的功能
2、参考模型：
	ISO/OSI(开放式系统互联参考模型)七层参考模型：
		应用层
		表示层
		会话层
		传输层
		网络层
		数据链路层
		物理层
	TCP/IP（传输控制协议/因特网互联协议，又名网络通讯协议）参考模型：
		应用层
		传输层
		网络层
		网络接口层
ping命令是属于网络层，用到的是ICMP协议：internet控制协议，是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息
3、网际协议栈
	应用层：支持网络应用，报文传送。HTTP(超文本传输协议) FTP（文件传输协议） SMTP（简单邮件传输协议）
	传输层：主机进程间数据段传送。TCP UDP
	网络层：主机（源目标）间分组传送。ip协议，路由协议
	数据链路层：相邻网络节点间的数据帧传送。ppp（点对点协议） ethernet
	物理层：物理介质上的比特传送
4、网络应用程序体系结构
	（1）客户机/服务器体系结构
		服务器主机总是打开
		服务器具有固定的、众所周知的IP地址
		客户机具有动态的IP地址
		客户机之间不能通信
	（2）P2P体系结构
		没有总是打开的服务器
		任意一对主机之间可以直接通信
		对等间歇连接，可以改变ip地址
	（3）客户机、服务器和P2P混合体系结构
		文件在对等方之间相互交换、文件搜索通过服务器
		两个聊天用户之间是P2P、注册和查询通过服务器
5、HTTP协议
	http://baidu.com/path/xxx/yyy   协议 ipport 路径名
	（1）什么是http
		http，超文本传输协议，web的应用层协议，采用客户机/服务器的模式。协议的本质是对信息传输内容和顺序的约定。HTTP协议就约定了客户端与服务器之间通信的标准
		http是无状态协议，服务器不维护客户先前的状态信息。也就是说：如果客户机第一次登录并且成功后，第二次登录，服务器仍然不会知道当前请求的是哪个用户
	（2）http连接
		非持久HTTP连接（短链接）：每个TCP连接只传送一个对象，下载多个对象需要创建多个TCP连接，HTTP/1.0使用短链接
		长连接：一个TCP连接可以传送多个对象，HTTP/1.1默认使用长连接
	（3）HTTP请求报文
		请求行：方法 URI 协议版本
		请求头：支持的语言 cookie等
		请求体：传输的参数
	（4）URI和URL的区别：URL是URI的子集，它们都定义了资源是什么。但有区别：URI可以唯一标识该对象，而URL不仅可以唯一标识该元素，还可以定位到它，所以叫统一资源定位符。举例：URI是身份证号，URL是身份证地址+姓名
	（5）常用方法：
		GET：从服务器获取指定数据
		POST：向服务器传送指定数据
		HEAD:服务器收到请求时返回响应信息，只包含head头部，不包含请求对象主体
		PUT:文件在实体主体中被上载到URL指定的路径
		DELETE:删除URL字段指定的文件
	（6）get方法与post方法的区别：
		get方法传输的参数直接放在url中，而post是放在请求体中
		get方法没有post方法安全
		get方法是从服务器获取数据，post是把需要处理的数据提交到服务器
		get方法回退是无害的，而post需要重新提交
		get方法传输的参数有长度限制，而post没有
		get方法只支持url编码，而post支持多种编码方式json xml
		get方法请求的历史记录会保存在浏览器历史记录中，而post不会
	（7）http响应状态码
		200 请求成功
		204 请求成功，但是没有数据，一般用在：只需要返回是否成功的情况
		301 永久性重定向，请求对象被永久迁移，新的url在响应首部用字段location指出
		302 临时性重定向，请求对象暂时迁移，新的url在响应首部用字段location指出
		400 bad request 该请求不能被服务器解读
		403 forbidden 拒绝访问。没有权限访问此网站
		404 not found 服务器上不存在所请求的对象
		500 内部服务器错误
		502 bad gateway 错误网关，可能是后台服务器没有起来，也可能是连接超时，连接过多，导致服务器无法给予正常的响应
	（8）什么是无效链接
		无效链接即死链接，也就是那些不可达的链接，通俗的理解是以前可以通过点击这个链接到达网站页面，后续可能由于网站迁移、改版、操作不当等原因，使得链接指向的目标页面不存在而无法访问，访问死链接时，一般会出现"抱歉，您所访问的页面不存在"的提示信息或者404状态页面
	（9）http与https
		http:是超文本传输协议，是以明文方式传输数据的，没有提供任何数据加密，并且不会验证通信方的身份
		https:是安全套接字层超文本传输协议，是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http安全
		注意：https协议并不是应用层的一种新的协议，只是在http通信接口部分用ssl协议代替而已。原本http与tcp之间直接进行通信，但是加入ssl后就先是http与ssl进行通信，再是ssl与tcp进行通信
		http与https的区别：
			HTTPS协议需要到CA（电子认证服务）申请证书。
			HTTP是超文本传输协议，HTTPS是更安全的SSL加密传输协议。
			使用完全不同的连接方式，端口也不同，HTTP使用80端口，而HTTPS使用443端口。
			HTTP连接很简单，是无状态的；HTTPS是由SSL + HTTP构建的可进行加密传输、身份认证的更安全的网络协议。
		ssl协议：
			SSL：位于TCP/IP协议与各种应用层协议之间。
		ssl协议基本内容
			SSL记录协议：建立在可靠传输协议的基础之上（如TCP），为高层协议提供数据封装、压缩、加密等基本功能。
			SSL握手协议：建立在SSL记录协议之上，在数据传输之前，双方进行身份验证、协商加密算法、交换加密密钥等。
		SSL协议原理
			公钥加密法。客户端向服务端索要公钥，收到后用自己的私钥加密信息，服务端收到密文后用自己的私钥解密。
6、cookie和session
	1、存放位置不同，cookie数据存放在客户的浏览器上，session数据放在服务器上
    2、安全程度不同，cookie不是很安全，别人可以分析存放在本地的cookie并进行欺骗，考虑到安全应当使用session
    3、性能使用程度不同，session会在一定时间内保存在服务器上，当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应用用cookie
    4、数据存储大小不同，单个cookie保存的数据 不能超过4k，很多浏览器都限制一个站点最多保存20个cookie，而session则存储在服务端，浏览器对其没有限制
7、DNS域名服务
	（1）DNS是什么
		DNS是域名系统，是因特网的目录服务，主机、路由器有多种标识符，包括主机名和ip地址。主机名是为了方便人类记忆创建的，是拿给人看的，而ip地址才是用于分组寻址的，因为它是固定的长度：32bit，更加规范、路由器更加容易接受。所以我们需要一个转换器，来将主机名转换为ip地址。
		从实体上看：是种由分层DNS服务器实现的分布式数据库
		从协议上看：是一种实现域名转换的应用层协议

	（2）DNS提供什么功能
		1、提供主机名到ip地址映射的查询服务（核心功能）
		2、提供主机别名服务。一个复杂的主机可能有一个规范主机名和多个主机别名，主机别名比规范主机名更容易记忆。DNS提供根据主机别名查找规范主机名的服务
		3、负载分配。对于被频繁访问的大型站点来说，它可能有多台服务器，那这时主机与ip就不再是一一对应了，而是一个主机名对应多个ip地址。在大量的、连续多次访问中，DNS通过旋转ip地址来实现负载均衡。当客户机进行DNS请求时，DNS服务器便会把全部的ip地址放在响应报文中应答，但在不同的回答中它会旋转这些ip地址的顺序，客户机总会向排在最前面的ip地址发出请求
	（3）DNS服务器
		根DNS服务器
		顶级DNS服务器
		权威DNS服务器
		本地DNS服务器
	（4）DNS是怎么工作的
		DNS有两种查询方式：递归查询和迭代查询，从主机到本地DNS服务器是递归查询；本地DNS服务器向另外三个服务器的查询是迭代查询
		在迭代查询过程中，被查询的名字服务器回复可以被查询的名字服务器的ip地址。也就是说，它总是在告诉本地DNS服务器，"我不知道它的名字，但是你可以问xxx服务器"
	（5）DNS解析ip地址的详细过程：
		1. 浏览器先检查自身缓存中有没有被解析过的这个域名对应的ip地址，如果有，解析结束。同时域名被缓存的时间也可通过TTL属性来设置。
		2. 如果浏览器缓存中没有（专业点叫还没命中），浏览器会检查操作系统缓存中有没有对应的已解析过的结果。而操作系统也有一个域名解析的过程。在windows中可通过c盘里一个叫hosts的文件来设置，如果你在这里指定了一个域名对应的ip地址，那浏览器会首先使用这个ip地址。
		3.  如果至此还没有命中域名，才会真正的请求本地域名服务器（LDNS）来解析这个域名，这台服务器一般在你的城市的某个角落，距离你不会很远，并且这台服务器的性能都很好，一般都会缓存域名解析结果，大约80%的域名解析到这里就完成了。
		4. 如果本地域名服务器仍然没有命中，就直接跳到根域名服务器请求解析
		5. 根域名服务器返回给本地域名服务器一个所查询域的顶级域名服务器主域名服务器（gTLD Server，国际顶尖域名服务器，如.com .cn .org等）地址
		6. 此时LDNS再发送请求给上一步返回的gTLD
		7. 接受请求的gTLD查找并返回这个域名对应的Name Server的地址，这个Name Server就是网站注册的域名服务器
		8. Name Server根据映射关系表找到目标ip，返回给LDNS
		9. LDNS缓存这个域名和对应的ip
8、DNS是使用TCP还是UDP协议：
	DNS同时占用tcp和udp的53端口
	1、区域传递时使用tcp：辅域名服务器会定时向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。区域传送将使用TCP而不是UDP，因为数据同步传送的数据量比一个请求和应答的数据量要多得多；另外tcp是一种可靠的连接，保证了数据的准确性
	2、域名解析时使用udp协议：客户端向DNS服务器查询域名，一般返回的内容不超过512字节，用UDP传输即可。不用经过TCP三次握手，这样DNS服务器负载更低，响应更快。
8、传输层服务
	在两个不同的主机上运行的应用程序之间提供的逻辑通信
	传输层协议运行在端系统：
		发送方：将应用程序报文数据段发送给网络层
		接收方：将数据段重新整理成报文发送给应用层
9、UDP协议：
	什么是UDP协议
		用户数据报协议，是一种无连接的传输协议，它只在ip数据报服务之上提供很少一点的功能：即端口功能和差错检测功能。所以它是无修饰、不加渲染、尽最大努力服务，因此可能会出现的问题
			丢失
			报文失序
		UDP的无连接体现在：
			接收者与发送者之间没有握手
			每一个UDP数据段的处理独立于其他的数据段（支持一对一、一对多、多对一的数据通信）
		从UDP可能出现的问题看起来它很糟糕，那为什么它依然出现并使用着？（优点）
			不需要建立链接，所以能减少延迟
			要求简单，发送者与接收者之间不需要保持连接状态
			很小的数据段首部
			没有拥塞控制，会以尽可能快的速度传输
10、TCP协议：
	（1）什么是TCP？
		TCP是面向连接的、可靠的、基于字节流的传输协议。它提供的功能和特性：
			一对一，即一个发送者、一个接收者
			可靠按序的字节流
			流水线：TCP拥塞控制和流量控制设置窗口大小
			收发缓冲区
			全双工数据：同一个连接上的双向数据流
			面向连接：在数据交换前握手，初始化发送方和接收方的状态
			流量控制:发送方不会淹没接收方
	（2）为什么TCP是三次握手，而不是两次
		防止失效的连接请求报文又传回到主机B
		假定是两次握手，主机A发送一个连接请求给主机B，但是它在网络节点滞留了，没有收到确认，所以A就又发送了一个连接请求，这一次主机B收到了SYN确认，并且发送ACK确认号给主机A，于是它们俩建立了连接并传输数据。当数据传输完毕后，它们关闭了连接。而此时，失效的连接请求可能又重新传到了主机B，它以为A又想和它连接了，于是就发送了确认号，如果是两次握手的话那么连接就建立了，主机B于是开始一直等待A传输数据，但是事实上A并不知道他们在连接，所以会导致主机B浪费了资源
	（3）TCP如何保证数据的可靠性：
	    1、校验和：
	        发送的数据包的二进制相加然后取反，目的是检测数据在传输过程中有没有发生变化，如果收到段的校验和有差错，tcp将丢弃这个报文段或是不确认接收到此报文段
	    2、确认应答+序列号：
	        Tcp给发送的每一个包进行编号，接收方对收到的数据包进行排序，把有序数组传送给应用层
	    3、超时重传
	        当tcp发送一个段后，启动计时器，等待目地端确认接收到此报文段，如果不能及时收到确认，将重新发送此报文段
	    4、流量控制
	        TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP使用的流量控制协议是可变大小的滑动窗口协议。TCP根据接收端对数据的处理能力，决定发送端的发送速度，这个机制就是流量控制。
	        接收方有即时窗口（滑动窗口），随ACK报文发送
	    5、拥塞控制
	        当网络拥塞时，减少数据的发送，发送方有拥塞窗口，发送数据前比对接收方发过来的即时窗口，取小的

	        我们知道tcp通过一个定时器（timer）采样了RTT（客户端到服务器往返时间）并计算RTO（重传超时时间），但是，如果网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，然而重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这就导致了恶行循环，最终形成‘网络风暴’--TCP的拥堵控制机制就是用于应对这种情况

		    首先需要了解一个概念，为了在发送端调节所要发送的数据量，定义了一个‘拥堵窗口’，在发送数据时，将拥堵窗口的大小与接收端ack的窗口大小作比较，取较小者作为发送数据量的上限

		    拥堵控制主要是4个算法：
		    1、慢启动：意思是刚刚加入网络的连接，一点一点的提速，不要一上来就把路占满
		        连接建立好的开始先初始化cwnd = 1,表明可以传一个mss大小的数据
		        每当收到一个ack,cwnd++呈线性上升
		        每当过了一个RTT，cwnd=cwnd*2,呈指数上升
		        阈值ssthresh，是一个上限，当cwnd>=ssthresh时，就会进入拥堵避免算法
		    2、拥塞避免：当拥塞窗口cwnd达到一个阈值时，窗口大小不再以指数上升，而是以线性上升，避免增长过快导致网络拥塞
		    3、快重传：在收到3个duplicated acks（重复确认）时就开启重传，而不用等到RTO超时
		    4、快速恢复：至少收到了3个duplicated acks，说明网络也没有那么糟糕，可以快速恢复

	（4）TCP拥塞控制与流量控制（先注意，拥塞控制 不等于 流量控制）
		什么是流量控制
			tcp连接的接收方有一个接收缓冲区。应用程序可能从这个缓冲区读出数据很慢，因此需要保证发送速率和接收应用程序的提取速率匹配，发送方不能发送的太多太快，让接收缓冲区溢出。流量控制使用接收窗口（即接收缓冲区的剩余空间），接收方在报文段中告知接收窗口的剩余空间，发送方需要限制没有被确认的数据不能超过接收窗口，从而保证接收缓冲区不溢出
			滑动窗口：接收数据端使用的窗口大小，用来告知发送端它的缓冲大小，以此可以控制发送端发送数据的大小，从而达到流量控制的目的（由于tcp是全双工连接，因此发送方和接收方都有滑动窗口）

	（5）什么是拥塞控制
			从信息角度看，拥塞是："太多源主机发送太多的数据，速率太快以至于网络来不及处理"。表现为：丢失分组（路由器的缓冲区溢出）、长延迟（在路由器的缓冲区排队）
			拥塞窗口：发送数据端使用的窗口大小，拥塞窗口不代表缓存，拥塞窗口指某一源端数据流在一个RTT内可以最多发送的数据包数
			拥塞控制是防止过多的数据注入网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制是一个全局性的过程，和流量控制不同，流量控制指点对点通信量的控制
		tcp的4种拥塞控制算法：
			（1）慢启动
			（2）拥塞避免
			（3）快重传
			（4）快恢复
	（6）搜索敏感词汇时，页面被重置的原理
		关键字检测，针对明文或者base64等弱加密通信内容，与准备好的敏感词库进行匹配，当发现敏感词时，将服务器发回的SYN/ACK，确认号x+1包改成SYN/ACK,确认号：0，这代表TCP连接被重置，用户便主动放弃了连接，提示连接失败。让用户误认为服务器拒接连接，而主动放弃继续与服务器连接，自动阻断记录含有敏感词的网页
	（7）浏览器输入域名发生了什么？（web请求过程）
		如果hosts文件没有，浏览器会查看自己的缓存
		浏览器会从主机的hosts文件中查看是否有该域名和ip地址的映射   （hosts就是将一些常用的网址域名与其对应的IP地址建立一个关联“数据库）
		当上面两个方法都行不通时，只能去请求DNS服务器来获取IP地址
			    先使用ARP获取默认网关的mac地址
			    组织数据发送给默认网关
			    默认网关有转发数据的能力，把数据转发给路由器
			    路由器根据自己的路由协议，来选择一个合适的较快的路径转发数据给目的网关
			    目的网关（dns服务器所在的网关），把数据转发给dns服务
			    dns解析出baidu对应的ip地址，并原路返回请求这个域名的浏览器
		获取到IP地址后，建立tcp连接、三次握手
		确认连接后发送一个http请求报文
		服务器处理请求，并对请求做出响应
		浏览器收到服务器响应，得到html代码
		tcp四次挥手断开链接
		渲染页面（浏览器根据响应报文来解析css样式、js交互等等）

		1. 由域名→IP 地址
		寻找 IP 地址的过程依次经过了浏览器缓存、系统缓存、hosts文件、路由器缓存、 递归搜索根域名服务器。
		2. 建立 TCP/IP 连接（三次握手具体过程）
		3. 由浏览器发送一个 HTTP 请求
		4. 经过路由器的转发，通过服务器的防火墙，该 HTTP 请求到达了服务器
		5. 服务器处理该 HTTP 请求，返回一个 HTML 文件

		6. 浏览器解析该 HTML 文件，并且显示在浏览器端
	（8）ARP的过程：
		（1）首先，每个主机都会在自己的arp缓冲区中建立一个arp列表，以表示ip地址和mac地址之间的对应关系
		（2）当源主机要发送数据时，首先检查arp列表中是否有对应ip地址的目的主机的mac地址，如果有，则直接发送数据，如果没有，就向本网段的所有主机发送arp数据包，该数据包包括的内容有：源主机ip地址，源主机mac地址，目的主机ip地址
		（3）当本网络的所有主机收到该arp数据包时，首先检查数据包中的ip地址是否是自己的ip地址，如果不是，则忽略数据包，如果是，则首先从数据包中取出源主机的ip和mac地址写入到arp列表中，如果已经存在，则覆盖，然后将自己的mac地址写入arp相应包中，告诉源主机自己是它想要找的mac地址
		（4）源主机收到arp响应包后，将目的主机的ip和mac地址写入arp列表，并利用此信息发送数据。如果源主机一直没有收到arp响应数据包，表示arp查询失败
	（9）DHCP：
		定义：动态主机配置协议，是一个局域网的网络协议，使用UDP协议工作，常用的2个端口：67（DHCP server）,68(DHCP client).DHCP通常被用于局域网环境，主要作用是集中的管理，分配ip地址，使client动态的获得ip地址、gateway地址、dns服务器地址等信息，并能够提升地址的使用率。简单来说，DHCP就是一个不需要账号密码登录的、自动给内网机器分配ip地址等信息的协议
		DHCP的工作流程：
			（1）客户端广播DHCP Discover消息
			（2）服务端提供地址租约（offer）
			（3）客户端选择并请求地址租用(request)
			 (4) 服务器确认将地址租用给客户端（ACK）
	（10）IP地址的分类
		A类：（1.0.0.0-126.0.0.0）（默认子网掩码：255.0.0.0或0xFF000000）第一个字节为网络号，后三个字节为主机号。该类ip地址的最前面为"0",所以地址的网络号取值于1~126之间。一般用于大型网络
		B类：（128.0.0.0-191.255.0.0）（默认子网掩码：255.255.0.0或0xFFFF0000）前两个字节为网络号，后两个字节为主机号。该类IP地址的最前面为"10",所以地址的网络号取值于128~191之间。一般用于中等规模网络
		C类：（192.0.0.0-223.255.255.0）（子网掩码：255.255.255.0或0xFFFFFFF00）前三个字节为网络号，最后一个字节为主机号。该类ip地址的最前面为"110"，所以地址的网络号取值于192~223之间。一般用于小型网络
		D类：是多播地址。该类IP地址的最前面为"1110",所以地址的网络号取值于224~239之间。一般用于多路广播用户。
	（8）发送FIN终止字段表明没有数据可发了，那为什么还要发送提示数据的序号字段呢
		因为当客户机/服务器发送FIN字段后，它还希望收到服务器向客户端发来的确认信息，那么如何指定接收的那条确认信息的序号呢？就得先在发送FIN时就初始化本数据段的序号，而这个数据段里面得数据部分就是特殊得一字节
	（9）关闭连接时，为什么客户端最后还要等2MSL的时间
		MSL：报文段最大生存时间。是任何IP数据报在因特网中存活的最大时间，超过这个时间ip数据报就会被丢弃，TCP允许设置不同得MSL值。
		等待2MSL的好处：
			1、保证TCP协议的全双工连接能够可靠关闭。保证客户端发送的最后一个ACK数据段能够到服务器。因为这个ACK有可能丢失，那么服务器收不到确认号，它就会再发送一次FIN，而客户机就能在这2MSL的时间中收到服务器传来的报文，再给出ACK回应，此时会重启2MSL计时器
			2、保证本次连接的重复数据段从网络消失。防止在三次握手中提到的失效的连接请求段又重新回到主机B出现在本连接中。因为在传输过程中有可能存在滞留数据段，如果客户机发送完最后一个ACK就直接关闭了，然后立马开启一个新连接，而如果这个新连接的端口号恰好和刚刚是一样的，那么当建立了新连接后，上一次连接中滞留的数据段可能会再次到达服务器，而服务器就会以为它是这一次连接中发送的数据，然而并不是。所以需要等待2MSL，使本次连接网络中滞留的数据段全部消失
	（10）为什么是四次握手
		四次握手和三次握手最大的区别在于中间部分，建立连接时服务器端发送确认号是把SYN和ACK放在一个数据段中发送，而关闭连接时ACK和FIN分成两个数据端传送的。所以关闭连接就比建立连接多出了一个数据段。那为什么关闭连接时不能也把ACK和FIN合在一起传送呢，原因是，当客户机发起关闭链接时，仅仅表示它不再传送数据了，但它仍接收数据，而这时服务器可以立即关闭，也可以在发送剩余的数据之后再传送FIN字段来关闭，所以说ACK和FIN往往分开发送

	（11）什么时候应该使用tcp,什么时候使用udp
		tcp：当对网络通讯质量要求的时候，整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用。比如：http,https,ftp,smtp。在日常生活中，常见使用的tcp协议的应用如下：浏览器、采用FTP的outlook，采用ssh的qq文件传输
		udp:当对网络通讯质量要求不高的时候，要求网络通讯速度经可能的快，这时就要用udp。比如：qq语音，qq视频
	（12）TCP和UDP的区别：
		共同点：都是传输层协议
		不同点：
			tcp：传输控制协议，面向连接，提供可靠的字节流服务，保证数据能从一端传到另一端，适用于传输大量数据，可靠性高的场合
			udp:用户数据报协议，面向数据报，不提供可靠性，但传输速率快，适用于一次只传输少量数据、对可靠性要求不高的应用环境
	（13）TCP长连接和短连接的区别：
		长连接：指在一个tcp连接上可以连续发送多个数据包，在tcp数据保持期间，如果没有数据包发送，定时发送数据包（心跳），以维持连接状态
				连接->数据传输->保持连接(心跳)->数据传输-->保持连接（心跳）-->...-->关闭连接（一个tcp连接通道多个读写通信）
		短连接：是指通信双方有数据交互时，就建立一个tcp连接，数据发送完成后，则断开此tcp连接（管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段）
		应用：
			短连接：web网站的http服务一般采用短连接
			长连接：（操作频繁，点对点的通讯）数据库的连接,smtp,网络游戏
11、网络层
	网络层提供的两个主要功能：
		转发：将分组从路由器的输入端口转移到正确的路由器输出端口
		路由：确定分组从发送方传输到接收方（目的主机）所经过的路径（或路由）
	ip协议：是用于报文交换网络的一种面向数据的协议，是网络层通信的标准协议，它负责提供基本的数据段传送功能，让每一块数据段都能够到达目的主机，但不检查是否被正确接收
	tcp和udp用一个端口发送信息是否冲突？
		不会冲突，因为在ip数据报首部有'高层'字段，它定义了传输层的协议。而客户机和服务器会根据ip数据报和tcp/udp报文段中提供的：传输协议、源目的主机、。。来判别接收者
	ip地址分类：
		ipv4:32个二进制（4字节）常用点分十进制表示
		ipv6:128个二进制（16字节）常用冒号分割表示
12、路由协议
	互联网是由不同的路由器将不同的子网连接、构成的网络的网络
	路由表保证数据包能够通过不同的路由器辗转最终到达目标主机
	路由协议就是负责路由器与路由器之间实时的信息交换、以实时动态控制路由表结构的协议
	RIP：路由信息协议
		是一种比较简单的内部网关协议，主要用于规模较小的网络。基于距离矢量算法的协议
	OSPF：开放最短路径优先协议
		属于链路状态路由协议，提出了区域的概念。每个区域中所有路由器维护着一个相同的链路状态数据库，通过最短生成树算法计算得到路由表
13、数据链路层协议：
	Ethernet协议、frame relay协议 ppp协议（点对点协议） ARP协议（地址解析协议，OSI模型中属于链路层，TCP/IP协议属于网络层）

15、播放视频很卡可能有什么原因：
	（1）局域网有问题
	（2）播放器不稳定
	（3）视频过大，解析慢
	（4）UDP传输中丢包
	（5）服务器端响应慢
	 (6) 信道繁忙到一定程度也会造成用户感到延迟卡顿等现象
	 视频文件本身的问题：
	 		文件码流是否正常--在出现花屏的地方逐帧播放---是否有丢帧--建议采用编码时增加冗余（差错检测）
	 		视频文件与播放器不兼容
	 局域网出问题：
	 		多台电脑共享上网，争抢网络流量
	 		视频所占带宽是比较高的，信道繁忙到一定程度也会造成用户感到延迟卡顿等现象
	 		网络不稳定：测网速看看
	 播放器本身的问题：
	 		有bug
	 		视频过大，解析慢
	 		一些播放器没有采用码流平滑技术，流量突发的时候，瞬时带宽一下子增大好多倍
	 		稳定性不好
	 		兼容性不好
	 服务器传输到客户端过程中出问题：
	 		udp传输过程中有问题--丢包，报文失序
	 服务器的问题：
	 		响应慢
14、app链接点击进来后加载一段时间后仍然没有内容，分析可能的原因
	（1）网络信号差
	（2）DNS解析慢
	（3）建立链接慢：当我们获取到服务器ip后，客户端和服务器建立连接，这个链接的速度与质量取决于线路的优劣。最常见的问题就是跨线路访问，地理位置相差很远的访问，中继网络异常等等。排查方法：如果ping一个网址，存在大量丢包或者很高延迟，就会导致访问的连接线路异常
	（4）服务器响应慢：cpu,内存，磁盘，带宽达到某一个瓶颈
	（5）本身问题，加载速度慢：当用户访问一个网站的时候，服务器会客户端发送大量的内容，这会占用大量的服务器带宽。带宽就是最常见也是最直接影响打开的因素
16、ping不通的常见原因和故障检查？
	（1）ping 127.0.0.1
		127.0.0.1是本地循环地址，如果本地址无法ping通，则表明本地机tcp/ip协议不能工作
	（2）ping 本机的ip地址
		用ipconfig查看本机ip,然后ping该ip,通则表明网络适配器（网卡或MODEM）工作正常，不通则是网络适配器出现故障
	（3）ping 同网段计算机的ip地址
		ping一台同网段计算机的ip,不通则表明网络线路出故障；若网络中还包含有路由器，则应先ping路由器在本网段端口的ip，不通则此段线路有问题；通则再ping路由器在目标计算机所在网段的端口ip,不通则是路由器出现故障；通则再ping目的机ip地址
	（4）ping 网址
		若要检测一个带DNS服务的网络，在上一步Ping通了目标计算机的IP地址后，仍无法连接到该机，则可ping该机的网络名，比如 Ping sina.com.cn，正常情况下会出现该网址所指向的IP，这表明本机的DNS设置正确而且DNS服务器工作正常，反之就可能是其中之一出 现了故障；同样也可通过Ping计算机名检测WINS解析的故障（WINS是将计算机名解析到IP地址的服务）。
15、什么是防火墙：
	防火墙对流经它的网络通信进行扫描，这样能够过滤掉一些攻击，以免其在目标计算机上被执行。防火墙还可以关闭不使用的端口。而且它还能禁止特定端口的流出通信，封锁特洛伊木马。最后，它禁止来自特殊网站的访问，从而防止来自不明入侵者的所有通信
16、进程与线程：
	进程是代码在数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位
	线程是进程的一个执行路径，一个进程中至少有一个线程，进程中的多个线程共享进程的资源
	二者关系：
		一个进程中有多个线程，多个线程共享进程的堆和方法区资源，但每个线程有自己的栈区域和程序计数器
	二者区别：
		进程：有独立的地址空间，一个进程崩溃掉，在保护模式下不会对其他进程产生影响
		线程：是一个进程中的不同执行路径，线程有自己的栈和局部变量，但线程没有独立的地址空间，一个线程死掉就整个进程死掉
17、进程 线程 协程
	进程：
		是具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源和调度的基本单位。每个进程都有自己独立的内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销比较大，但相对比较稳定安全
	线程：
		线程是指进程内的一个执行单元,也是进程内的可调度实体。线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。
	协程：
		协程是一种用户态的轻量级线程，协程的调度完全由用户控制。从技术的角度来说，“协程就是你可以暂停执行的函数”。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。
18、线程和协程的区别
	1) 一个线程可以多个协程，一个进程也可以单独拥有多个协程。
	2) 线程进程都是同步机制，而协程则是异步。
	3) 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态。
	4）线程是抢占式，而协程是非抢占式的，所以需要用户自己释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。
	5）协程并不是取代线程, 而且抽象于线程之上, 线程是被分割的CPU资源, 协程是组织好的代码流程, 协程需要线程来承载运行, 线程是协程的资源, 但协程不会直接使用线程, 协程直接利用的是执行器(Interceptor), 执行器可以关联任意线程或线程池, 可以使当前线程, UI线程, 或新建新程.。
	6）线程是协程的资源。协程通过Interceptor来间接使用线程这个资源。	

19、	TCP与HTTP的区别和联系
	TCP对应于传输层，HTTP对应于应用层，从本质上来说，二者没有可比性

	http协议是建立在TCP协议基础之上的，当浏览器需要从服务器获取网页数据的时候，会发出一次http请求。http会通过tcp建立起一个到服务器的连接通道，当本次请求需要的数据完毕后，http会立即将TCP连接断开，这个过程是很短的。所以http连接是一种短连接，是一种无状态连接

	tcp是底层协议，定义的是数据传输和连接方式的规范
	http是应用层协议，定义的是传输数据的内容的规范

	http协议中的数据是利用tcp协议传输的。所以支持http就一定支持tcp
19、线程的启动和停止：
	启动：thread.start()
	暂停：thread.suspend()
	退出：thread.abort()
20、僵尸进程和孤儿进程：
	僵尸进程：一个进程使用frok创建子程序，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述仍然保存在系统中。这种进程称之为僵尸进程
	危害：如果进程不调用wait/waitpid的话，那么保留的那段信息就不会被释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。应当避免

	孤儿进程：一个父进程退出，而它的一个或多个进程还在运行，那么那些子进程将称为孤儿进程。孤儿进程将被init进程所收养，并由init进程对他们完成状态收集工作
	危害：孤儿进程没有父进程处理，这个重任就落到了init进程身上，因此孤儿进程不会有什么危害
21、进程之间的通信方式：
	（1）文件和记录锁定：为避免两个进程同时访问同一共享资源而引起访问和操作的混乱，在进程对共享资源进行访问前必须对其进行锁定，该进程访问完后释放，互斥
	（2）管道：提供了两个进程之间数据流动的一种方式，用于父子进程之间
	（3）消息队列：是由消息组成的链表，存放在内核中并由消息队列标识符表示。通过使用消息类型，进程可以按任何顺序读消息，或为消息安排优先级顺序
	（4）共享内存：通过信号灯实现存储共享
	消息传递（管道，FIFO,消息队列）
	同步（互斥量，条件变量，读写锁，文件和记录锁定，信号量）
	共享内存（匿名和具名的）
进程间的八种通信方式----共享内存是最快的 IPC 方式 
1.无名管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
2.高级管道(popen)：将另一个程序当做一个新的进程在当前程序进程中启动，则它算是当前程序的子进程，这种方式我们成为高级管道方式。
3.有名管道 (named pipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
4.消息队列( message queue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
5.信号量( semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
6.信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
7.共享内存( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。
8.套接字( socket ) ： 套解字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。

22、线程之间的通信方式：
	（1）锁机制
	（2）信号量机制	
23、进程的5个状态：
	创建：进程正在创建，还不能运行。操作系统在创建线程时要进行的工作包括分配和建立进程控制块表项、建立资源表格并分配资源、加载程序并建立地址空间
	就绪：时间片已用完，此线程被强制暂停、等待下一个属于它的时间片的到来
	运行：此线程正在执行，正在占用时间片
	阻塞：也叫等待状态，等待某一事件执行完
	退出：进程死亡，释放操作系统资源
24、并行和并发：
	并行是指两个或者多个事件在同一时刻发生；
	并发是指两个或多个事件在同一时间间隔发生（交替执行）。
25、物理地址和虚拟地址：
	物理地址空间
		是实在的存在于计算机中的一个实体，在每一台计算机中保持唯一独立性。我们可以称它为物理内存；如在32位的机器上，物理空间的大小理论上可以达到2^32字节（4GB），但如果实际装在的内存不够4GB，那么有效的物理地址将会更少。
	虚拟地址：
		不真实存在于计算机中，每个进程都分配有自己的虚拟空间，而且只能访问自己被分配使用的空间。理论上，虚拟空间受物理内存大小的限制，如给有4GB内存，那么虚拟地址空间的地址范围就应该是0x00000000~0xFFFFFFFF(4GB)。
	虚拟地址与物理地址关系
	    对于内核物理内存映射区的虚拟内存（用kmalloc(), __get_free_pages申请的），使用virt_to_phys()和phys_to_virt()来实现物理地址和内核虚拟地址之间的互相转换。它实际上，仅仅做了3G的地址移位。上述方法适用于常规内存（内核物理内存映射区），高端内存的虚拟地址与物理地址之间不存在如此简单的换算关系。因为它涉及到了分离物理页的页表控制机制。
21、什么是web缓存，为什么要使用它
	web缓存游走于服务器和客户端之间，在两者之间搞监控，监控请求，并把请求输出的内容另存一份，如果下一个请求是相同的URL，则直接请求保存的副本，而不是直接麻烦源服务器
	优点：
		降低延迟：缓存离客户端更近，因此，请求速度更快，网站就显得更灵敏
		降低网络传输：副本被重复使用，大大降低了用户的带宽使用，同时保证了带宽请求在一个低水平上，更容易维护
22、cpu缓存
	cpu缓存：是位于cpu与内存之间的临时存储器，它的容量比内存小的多但是交换速度却比内存要快得多
	按照数据读取速度与cpu结合的紧密速度，cpu缓存可以分为一级缓存、二级缓存，cpu要读取数据时，首先在一级缓存中查找，没有找到再去二级缓存中找，每级缓存的命中率在80%左右


24、操作系统的调度策略：
	一、先来先服务调度算法（FCFS）：
		每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理器，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机
	二、短作业优先调度算法（SJF）:
		是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行
	三、短进程优先调度算法（SPF）
		是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度
	四、高优先权优先调度算法
		（1）非抢占式优先权算法：
			在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。
		（2）抢占式优先权调度算法：
			在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。
	五、基于时间片的轮转调度算法：
		在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几ms 到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。
25、负载均衡器：
	一、概念/作用：
		并发量不大的时候不建议采用负载均衡，毕竟需要多台服务器来支撑，成本也是非常高昂的
		但是用户量大的时候，服务器承载压力就会变大，就很有可能崩
		负载均衡之后，每台服务器都可以承担压力，就算其中一台服务器挂了，还有其他服务器来支持，也不会导致系统停运，请求地址在用户看来是一样的，只是后台请求的是不同服务器，用户无感知变化
	二、nginx配置负载均衡
		大家需要需要准备三台安装上nginx的服务器，配置过程不会太复杂；
		1.打开nginx的配置文件(nginx.conf)，修改以下配置
		2.重启nginx服务器，输入service nginx restart 即可！
	三、负载均衡的策略机制
		1.轮询（默认）
		请求依次轮流往每个应用服务器上进行分配，分配策略比较简单。 
		缺点：不均匀，可能会出现，某些服务器接受的请求较重，负载压力重，有些负荷小，不可控。另外服务器之间需要进行session同步。
		2.权重轮询（权重越高，进入的几率越大）
		优点：可以根据情况进行调整。可控，仍然需要进行session同步。
		3.IP-Hash
		优点：无需进行session同步，固定IP会固定访问一台服务器。 
		缺点：恶意攻击，会造成某台服务器压垮。提供的服务不同，面向的地区不同，IP可能会出现集中，造成不均匀，不可控。
		4.Fair
		这种相当于自适应，会根据服务器处理请求的速度进行负载均衡分配。处理请求最早结束的，拿到下一个请求。看上去是不是很好。但是一般都不使用，说是考虑到网络不稳定因素。还有待研究。这种也需要进行session同步。
		5.URL-Hash 
		这种是根据URL进行hash，这样某些请求永远打某台服务器。利于利用服务器的缓存，但是可能由于URL的哈希值分布不均匀，以及业务侧重造成某些服务器压力大，某些负荷低。这种也需要进行session同步。



































